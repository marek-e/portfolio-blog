---
title: 'Minesweeper LLM Arena'
description: 'Projet de hackathon AI Gateway ‚Äî LLMs comp√©tition pour r√©soudre une partie de D√©mineur sur le m√™me plateau cach√©.'
featured: true
techStack: ['TypeScript', 'React', 'Vercel AI SDK', 'AI Gateway', 'Vercel', 'Next.js']
links:
  repo: 'https://github.com/marek-e/minesweeper-battle'
  demo: 'https://minesweeper-battle-mu.vercel.app'
publishDate: 2025-12-04
image: '/projects/minesweeper-battle.png'
imageAlt: 'Minesweeper LLM Arena logo'
status: 'in-progress'
---

Pour le lancement de AI Gateway, Vercel a organis√© un hackathon avec pour objectif de construire une application qui permette de comparer les performances de diff√©rents mod√®les LLM sur un m√™me probl√®me. Et il mettait √† disposition 5 euros de token.

J'ai choisi de cr√©er une application qui permette de comparer les performances de diff√©rents mod√®les LLM sur le jeu du D√©mineur.

1. **Interface de jeu** : La premi√®re √©tape a √©t√© de cr√©er l'interface de jeu dans un premier temps jouable par un humain.

2. **Page de configuration** : La page de configuration permet de choisir les mod√®les LLM √† comparer et de configurer les param√®tres du jeu.

3. **Backend** : Il permet de g√©n√©rer un plateau de jeu al√©atoire et de simuler le jeu de mani√®re d√©terministe. C'est lui qui va g√©rer la logique du jeu, g√©rer les interactions avec les mod√®les LLM gr√¢ce au toolkit AI Gateway. Une seule cl√© d'API permet de tester tous les mod√®les LLM.

4. **Page d'ar√®ne** : Page qui permet de retranscrire les diff√©rents coups jou√©s en temps r√©el par les mod√®les LLM et afficher les r√©sultats une fois que chaque mod√®le a termin√© de jouer.

5. **Page de replays** : Page qui permet de rejouer les diff√©rents coups jou√©s par les mod√®les LLM et compater chaque decision coup par coup.

6. **Page d'historique** : J'ai ajout√© un stockage redis pour stocker les r√©sultats de chaque partie. Cela permet de comparer les performances des mod√®les LLM au fil du temps et de revisiter les parties pass√©es.

7. **D√©ploiement sur Vercel** : J'ai d√©ploy√© l'application sur Vercel. Cependant ma 1√®re impl√©mentation effectuait toutes les parties √† la suite d'une requ√™te API vers mon backend et celui-ci ouvrait une connexion Server-Sent Events (SSE) vers l'interface de jeu pour afficher les r√©sultats en temps r√©el. Le probl√®me √©tait que les fonctions Vercel utilis√©es par les routes back d√©finies dans mon application Next.js d√©passaient le timeout de 300 secondes et ne permettaient pas d'aller au bout de la partie. J'ai donc modifi√© l'impl√©mentation pour que chaque partie soit jou√©e au coup par coup avec des allers-retours entre le backend et le frontend.

<Mermaid
  chart={`
flowchart TB
    subgraph Frontend["üü® Frontend"]
        setup["/setup"]
        arena["/arena"]
    end

    subgraph Backend["üü© Backend - Vercel Function"]
        api["API Routes"]
        timeout["‚ö†Ô∏è Timeout 300sec"]
    end

    subgraph Storage["üü¶ Upstash Redis DB"]
        redis[(Redis)]
    end

    subgraph AI["üü™ AI Gateway"]
        gateway["LLM Models"]
    end

    setup -->|"POST /api/battle"| api
    api -->|"createBattle"| redis
    arena -->|"GET /api/battle/[id]/stream"| api
    api -.->|"SSE: init"| arena
    api -.->|"SSE: move"| arena
    api -.->|"SSE: complete"| arena
    api -->|"generateText"| gateway

`}
caption="‚ùå Avant : Architecture SSE (timeout d√©pass√©)"
/>

<Mermaid
  chart={`
flowchart TB
    subgraph Frontend["üü® Frontend"]
        setup["/setup"]
        arena["/arena"]
    end

    subgraph Backend["üü© Backend - Vercel Function"]
        api["API Routes"]
        logic["get current position per model<br/>and generate prompt"]
    end

    subgraph Storage["üü¶ Upstash Redis DB"]
        redis[(Redis)]
    end

    subgraph AI["üü™ AI Gateway"]
        gateway["LLM Models"]
    end

    setup -->|"POST /api/battle"| api
    api -->|"createBattle"| redis
    arena -->|"GET /api/battle/[id]/move"| api
    api -.->|"getBattleById"| redis
    api --> logic
    logic -->|"generateText"| gateway
    gateway -.->|"move"| api
    api -.->|"move"| arena
    arena -.->|"loop until complete"| arena

`}
caption="‚úÖ Apr√®s : Architecture Polling (requ√™tes courtes)"
/>

8. **Optimisation des LLM** : J'ai optimis√© le prompt pour que les mod√®les LLM puissent jouer le jeu de mani√®re optimale. En leur explicitant les r√®gles du jeu et les contraintes, j'ai pu obtenir des r√©sultats plus satisfaisants. J'ai ensuite essay√© de leur authoriser de jouer plusieurs coups √† la suite pour gagner du temps.

Conclusion :
Certains mod√®les LLM ont r√©ussi √† r√©soudre le jeu avec des config facile mais pour des grilles plus grandes, les parties devenaient tr√®s longues et en substituant les mod√®les par d'autres, moins bons mais plus rapides, les parties se terminaient plus rapidement mais par une d√©faite.
